from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
import aiohttp
import json
import re
from typing import Optional, Tuple

@register("clocc_search", "YourName", "CloCCèµ„æºæœç´¢æ’ä»¶", "1.0.0")
class MyPlugin(Star):
    def __init__(self, context: Context):
        super().__init__(context)
        # å­˜å‚¨ç”¨æˆ·çš„æœç´¢ç»“æœï¼Œç”¨äºäº¤äº’å¼æŸ¥è¯¢
        self.user_search_results = {}
        # å­˜å‚¨ç”¨æˆ·çš„åˆ†é¡µä¿¡æ¯
        self.user_pagination = {}

    async def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–"""
        pass
    
    # æœç´¢åŠŸèƒ½ï¼šå½“æ¶ˆæ¯ä»¥"æœ"å¼€å¤´æ—¶è§¦å‘
    @filter.regex(r"^æœ(.+)")  
    async def search_handler(self, event: AstrMessageEvent):
        """æœç´¢å¤„ç†å™¨"""
        message_str = event.get_message_str().strip()
        user_id = event.get_sender_id()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æœç´¢å…³é”®å­—
        match = re.match(r"^æœ(.+)", message_str)
        if match:
            keyword = match.group(1).strip()
            if keyword:
                # å…ˆå‘é€æ­£åœ¨æœç´¢çš„æç¤ºæ¶ˆæ¯
                yield event.plain_result("ğŸ” æ­£åœ¨æœç´¢ï¼Œè¯·ç¨å... (à¹‘â€¢Ì€Ï‰â€¢Ìà¹‘)âœ§")
                
                # è°ƒç”¨æœç´¢æ¥å£
                result = await self.search_resources(keyword, user_id)
                yield event.plain_result(result)
            else:
                yield event.plain_result("è¯·è¾“å…¥è¦æœç´¢çš„å…³é”®è¯ï¼Œä¾‹å¦‚ï¼šæœç”µå½±")
        else:
            yield event.plain_result("æœç´¢æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ï¼šæœ+å…³é”®è¯")

    # å¤„ç†ç”¨æˆ·è¾“å…¥çš„ç¼–å·ï¼ˆè·å–è¯¦ç»†ä¿¡æ¯ï¼‰
    @filter.regex(r"^è·å–(\d+)$")  
    async def number_handler(self, event: AstrMessageEvent):
        """å¤„ç†ç”¨æˆ·è¾“å…¥çš„ç¼–å·"""
        message_str = event.get_message_str().strip()
        user_id = event.get_sender_id()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç¼–å·
        match = re.match(r"^è·å–(\d+)$", message_str)
        if match:
            try:
                index = int(match.group(1))
                search_results = self.user_search_results[user_id]
                # è·å–å½“å‰é¡µç ä¿¡æ¯
                pagination = self.user_pagination.get(user_id, {"page": 1, "per_page": 10})
                current_page = pagination["page"]
                per_page = pagination["per_page"]
                
                # è®¡ç®—å®é™…ç´¢å¼•ï¼ˆè€ƒè™‘åˆ†é¡µï¼‰
                actual_index = (current_page - 1) * per_page + index
                
                if 1 <= actual_index <= len(search_results):
                    # è·å–å¯¹åº”ç¼–å·çš„è¯¦ç»†ä¿¡æ¯
                    item = search_results[actual_index - 1]
                    title = item.get("note", "æœªçŸ¥æ ‡é¢˜")
                    url = item.get("url", "æœªçŸ¥é“¾æ¥")
                    password = item.get("password", "")
                    source = "ç™¾åº¦ç½‘ç›˜" if item.get("type") == "baidu" else "å¤¸å…‹ç½‘ç›˜"
                    
                    # å¦‚æœæ˜¯ç™¾åº¦ç½‘ç›˜ï¼Œå…ˆè°ƒç”¨è½¬æ¢æ¥å£
                    if item.get("type") == "baidu":
                        yield event.plain_result("ğŸ”„ æ­£åœ¨è·å–èµ„æºï¼Œè¯·ç¨å...é¢„è®¡éœ€è¦10ç§’å·¦å³ (Â´âˆ€ï½€)â™¡")
                        converted_result = await self.convert_baidu_link(url)
                        if converted_result:
                            # è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨æ–°é“¾æ¥
                            url = converted_result[0]
                            password = converted_result[1]
                            result = f"ğŸ” èµ„æºè¯¦æƒ…:\nğŸ“– æ ‡é¢˜: {title}\nğŸ”— æ¥æº: {source}\nğŸŒ é“¾æ¥: {url}"
                            if password:
                                result += f"\nğŸ”‘ å¯†ç : {password}"
                            yield event.plain_result(result)
                        else:
                            # è½¬æ¢å¤±è´¥ï¼Œæç¤ºé“¾æ¥å·²å¤±æ•ˆ
                            yield event.plain_result("âŒ æŠ±æ­‰ï¼Œè¯¥åˆ†äº«é“¾æ¥å·²å¤±æ•ˆï¼Œè¯·å°è¯•è·å–å…¶ä»–èµ„æº (ï¼›â€²âŒ’`)")
                    else:
                        # å¤¸å…‹ç½‘ç›˜ç›´æ¥æ˜¾ç¤ºè¯¦æƒ…
                        result = f"ğŸ” èµ„æºè¯¦æƒ…:\nğŸ“– æ ‡é¢˜: {title}\nğŸ”— æ¥æº: {source}\nğŸŒ é“¾æ¥: {url}"
                        if password:
                            result += f"\nğŸ”‘ å¯†ç : {password}"
                        yield event.plain_result(result)
                else:
                    yield event.plain_result(f"è¯·è¾“å…¥æœ‰æ•ˆçš„ç¼–å· (1-{min(per_page, len(search_results) - (current_page-1) * per_page)})")
            except ValueError:
                yield event.plain_result("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ç¼–å·")
        else:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰å¾…å¤„ç†çš„æœç´¢ç»“æœï¼Œåˆ™ä¸å¤„ç†æ•°å­—æ¶ˆæ¯
            pass

    # å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤ï¼ˆä¸åŠ æ–œæ ï¼‰
    @filter.regex(r"^ä¸‹ä¸€é¡µ$")  
    async def next_page_handler(self, event: AstrMessageEvent):
        """å¤„ç†ä¸‹ä¸€é¡µæŒ‡ä»¤"""
        user_id = event.get_sender_id()
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰å¾…å¤„ç†çš„æœç´¢ç»“æœ
        if user_id in self.user_search_results and self.user_search_results[user_id]:
            # è·å–åˆ†é¡µä¿¡æ¯
            if user_id not in self.user_pagination:
                self.user_pagination[user_id] = {"page": 1, "per_page": 10}
            
            pagination = self.user_pagination[user_id]
            current_page = pagination["page"]
            per_page = pagination["per_page"]
            search_results = self.user_search_results[user_id]
            
            # è®¡ç®—æ€»é¡µæ•°
            total_pages = (len(search_results) + per_page - 1) // per_page
            
            if current_page < total_pages:
                pagination["page"] = current_page + 1
                # æ˜¾ç¤ºæ–°é¡µé¢çš„ç»“æœ
                result = self.format_paginated_results(user_id, search_results, pagination)
                yield event.plain_result(result)
            else:
                yield event.plain_result("å·²ç»æ˜¯æœ€åä¸€é¡µäº†")
        else:
            yield event.plain_result("æ²¡æœ‰æœç´¢ç»“æœå¯ä»¥ç¿»é¡µ")

    # å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤ï¼ˆä¸åŠ æ–œæ ï¼‰
    @filter.regex(r"^ä¸Šä¸€é¡µ$")  
    async def prev_page_handler(self, event: AstrMessageEvent):
        """å¤„ç†ä¸Šä¸€é¡µæŒ‡ä»¤"""
        user_id = event.get_sender_id()
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰å¾…å¤„ç†çš„æœç´¢ç»“æœ
        if user_id in self.user_search_results and self.user_search_results[user_id]:
            # è·å–åˆ†é¡µä¿¡æ¯
            if user_id not in self.user_pagination:
                self.user_pagination[user_id] = {"page": 1, "per_page": 10}
            
            pagination = self.user_pagination[user_id]
            current_page = pagination["page"]
            
            if current_page > 1:
                pagination["page"] = current_page - 1
                # æ˜¾ç¤ºæ–°é¡µé¢çš„ç»“æœ
                search_results = self.user_search_results[user_id]
                result = self.format_paginated_results(user_id, search_results, pagination)
                yield event.plain_result(result)
            else:
                yield event.plain_result("å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†")
        else:
            yield event.plain_result("æ²¡æœ‰æœç´¢ç»“æœå¯ä»¥ç¿»é¡µ")

    async def search_resources(self, keyword: str, user_id: str) -> str:
        """è°ƒç”¨æœç´¢æ¥å£å¹¶è¿”å›ç»“æœ"""
        url = f"https://pansd.xyz/api/search?kw={keyword}&src=all&cloud_types=baidu%2Cquark"
        
        # å‡†å¤‡è¯·æ±‚å‚æ•°
        params = {
            "kw": keyword,
            "src": "all",
            "cloud_types": "baidu,quark"
        }
        
        headers = {
            "Content-Type": "application/json",
            "User-Agent": "AstrBot-Search-Plugin/1.0"
        }
        
        try:
            logger.info(f"æ­£åœ¨è°ƒç”¨æœç´¢æ¥å£: {url}")
            
            # è®¾ç½®è¶…æ—¶æ—¶é—´
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url, params=params, headers=headers) as response:
                    logger.info(f"æœç´¢æ¥å£å“åº”çŠ¶æ€ç : {response.status}")
                    
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"æœç´¢æ¥å£å“åº”æ•°æ®: {data}")
                        return self.format_search_results(data, keyword, user_id)
                    else:
                        error_text = await response.text()
                        logger.error(f"æœç´¢æ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, å“åº”å†…å®¹: {error_text}")
                        return f"æœç´¢å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status}"
        except aiohttp.ClientConnectorError as e:
            logger.error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
            return "æœç´¢å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°æœç´¢æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        except aiohttp.ClientError as e:
            logger.error(f"HTTPå®¢æˆ·ç«¯é”™è¯¯: {e}")
            return f"æœç´¢å¤±è´¥ï¼šç½‘ç»œè¯·æ±‚é”™è¯¯ {e}"
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æé”™è¯¯: {e}")
            return f"æœç´¢å¤±è´¥ï¼šè¿”å›æ•°æ®æ ¼å¼é”™è¯¯ {e}"
        except Exception as e:
            logger.error(f"æœç´¢æ¥å£è°ƒç”¨å¤±è´¥: {e}")
            return f"æœç´¢å¤±è´¥: {e}"

    async def convert_baidu_link(self, original_url: str) -> Optional[Tuple[str, str]]:
        """è½¬æ¢ç™¾åº¦ç½‘ç›˜é“¾æ¥"""
        convert_url = "http://103.109.22.15:5003/api/key/transfer-and-share"
        api_key = "oPhbkFvdYnuKxMOCsei7gLHVSoQ5cnmj1MCSNiir35s"
        
        headers = {
            "X-API-Key": api_key,
            "Content-Type": "application/json"
        }
        
        # å›ºå®šå¯†ç ä¸º1234
        data = {
            "share_url": original_url,
            "save_dir": "/pansou_downloads",
            "share_password": "1234",
            "share_period": 0
        }
        
        try:
            logger.info(f"æ­£åœ¨è½¬æ¢ç™¾åº¦ç½‘ç›˜é“¾æ¥: {original_url}")
            
            # è®¾ç½®è¶…æ—¶æ—¶é—´
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(convert_url, headers=headers, json=data) as response:
                    logger.info(f"è½¬æ¢æ¥å£å“åº”çŠ¶æ€ç : {response.status}")
                    
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"è½¬æ¢æ¥å£å“åº”æ•°æ®: {result}")
                        
                        if result.get("success"):
                            share_info = result.get("share_info", {})
                            converted_url = share_info.get("url", original_url)
                            converted_password = share_info.get("password", "1234")
                            return (converted_url, converted_password)
                        else:
                            logger.error(f"è½¬æ¢å¤±è´¥: {result.get('message')}")
                            return None
                    else:
                        error_text = await response.text()
                        logger.error(f"è½¬æ¢æ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, å“åº”å†…å®¹: {error_text}")
                        return None
        except aiohttp.ClientConnectorError as e:
            logger.error(f"è½¬æ¢æ¥å£ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
            return None
        except aiohttp.ClientError as e:
            logger.error(f"è½¬æ¢æ¥å£HTTPå®¢æˆ·ç«¯é”™è¯¯: {e}")
            return None
        except json.JSONDecodeError as e:
            logger.error(f"è½¬æ¢æ¥å£JSONè§£æé”™è¯¯: {e}")
            return None
        except Exception as e:
            logger.error(f"è½¬æ¢æ¥å£è°ƒç”¨å¤±è´¥: {e}")
            return None

    def format_search_results(self, data: dict, keyword: str, user_id: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        try:
            logger.info(f"å¼€å§‹æ ¼å¼åŒ–æœç´¢ç»“æœ: {data}")
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            if not data or "merged_by_type" not in data:
                return "æœªæ‰¾åˆ°ç›¸å…³èµ„æºã€‚"
            
            # åˆ†åˆ«è·å–ç™¾åº¦ç½‘ç›˜å’Œå¤¸å…‹ç½‘ç›˜çš„ç»“æœ
            merged_data = data.get("merged_by_type", {})
            baidu_results = merged_data.get("baidu", [])
            quark_results = merged_data.get("quark", [])
            
            if not baidu_results and not quark_results:
                return "æœªæ‰¾åˆ°ç›¸å…³èµ„æºã€‚"
            
            # æŒ‰ç…§ç½‘ç›˜ç±»å‹åˆ†ç»„å±•ç¤ºï¼ˆå…ˆ5æ¡ç™¾åº¦ï¼Œå†5æ¡å¤¸å…‹ï¼‰
            all_results = self.group_results_by_type(baidu_results, quark_results)
            
            # å°†æœç´¢ç»“æœå­˜å‚¨åœ¨ç”¨æˆ·ç¼“å­˜ä¸­
            self.user_search_results[user_id] = all_results
            # åˆå§‹åŒ–åˆ†é¡µä¿¡æ¯
            self.user_pagination[user_id] = {"page": 1, "per_page": 10}
            
            # è¿”å›ç¬¬ä¸€é¡µçš„ç»“æœ
            pagination = self.user_pagination[user_id]
            return self.format_paginated_results(user_id, all_results, pagination)
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æœç´¢ç»“æœå¤±è´¥: {e}")
            return f"ç»“æœæ ¼å¼åŒ–å¤±è´¥: {e}"

    def group_results_by_type(self, baidu_results: list, quark_results: list) -> list:
        """æŒ‰ç…§ç½‘ç›˜ç±»å‹åˆ†ç»„å±•ç¤ºç»“æœï¼ˆå…ˆ5æ¡ç™¾åº¦ï¼Œå†5æ¡å¤¸å…‹ï¼‰"""
        # åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—è¡¨æ¥å­˜å‚¨åˆ†ç»„åçš„ç»“æœ
        grouped_results = []
        
        # å…ˆæ·»åŠ ç™¾åº¦ç½‘ç›˜çš„ç»“æœï¼ˆæœ€å¤š5æ¡ï¼‰
        baidu_count = min(len(baidu_results), 5)
        for i in range(baidu_count):
            baidu_results[i]["type"] = "baidu"  # ç¡®ä¿æœ‰typeå­—æ®µ
            grouped_results.append(baidu_results[i])
        
        # å†æ·»åŠ å¤¸å…‹ç½‘ç›˜çš„ç»“æœï¼ˆæœ€å¤š5æ¡ï¼‰
        quark_count = min(len(quark_results), 5)
        for i in range(quark_count):
            quark_results[i]["type"] = "quark"  # ç¡®ä¿æœ‰typeå­—æ®µ
            grouped_results.append(quark_results[i])
        
        # å¦‚æœæŸç§ç±»å‹çš„ç»“æœä¸è¶³5æ¡ï¼Œç”¨å¦ä¸€ç§ç±»å‹çš„ç»“æœè¡¥å……
        total_added = len(grouped_results)
        if total_added < 10:
            remaining_slots = 10 - total_added
            # è¡¥å……ç™¾åº¦ç½‘ç›˜ç»“æœ
            if len(baidu_results) > baidu_count:
                for i in range(baidu_count, min(baidu_count + remaining_slots, len(baidu_results))):
                    baidu_results[i]["type"] = "baidu"
                    grouped_results.append(baidu_results[i])
                    remaining_slots -= 1
                    if remaining_slots <= 0:
                        break
            # è¡¥å……å¤¸å…‹ç½‘ç›˜ç»“æœ
            if remaining_slots > 0 and len(quark_results) > quark_count:
                for i in range(quark_count, min(quark_count + remaining_slots, len(quark_results))):
                    quark_results[i]["type"] = "quark"
                    grouped_results.append(quark_results[i])
                    remaining_slots -= 1
                    if remaining_slots <= 0:
                        break
        
        # ç»§ç»­æ·»åŠ å‰©ä½™çš„ç»“æœï¼Œä¿æŒåˆ†ç»„æ¨¡å¼ï¼ˆ5ä¸ªç™¾åº¦ï¼Œ5ä¸ªå¤¸å…‹ï¼‰
        baidu_index = max(baidu_count, 5)
        quark_index = max(quark_count, 5)
        
        while baidu_index < len(baidu_results) or quark_index < len(quark_results):
            # æ·»åŠ ä¸‹ä¸€ç»„ç™¾åº¦ç½‘ç›˜ç»“æœï¼ˆæœ€å¤š5æ¡ï¼‰
            baidu_added = 0
            while baidu_added < 5 and baidu_index < len(baidu_results):
                baidu_results[baidu_index]["type"] = "baidu"
                grouped_results.append(baidu_results[baidu_index])
                baidu_index += 1
                baidu_added += 1
            
            # æ·»åŠ ä¸‹ä¸€ç»„å¤¸å…‹ç½‘ç›˜ç»“æœï¼ˆæœ€å¤š5æ¡ï¼‰
            quark_added = 0
            while quark_added < 5 and quark_index < len(quark_results):
                quark_results[quark_index]["type"] = "quark"
                grouped_results.append(quark_results[quark_index])
                quark_index += 1
                quark_added += 1
            
            # å¦‚æœå…¶ä¸­ä¸€ç§ç±»å‹å·²ç»æ²¡æœ‰ç»“æœäº†ï¼Œç»§ç»­æ·»åŠ å¦ä¸€ç§ç±»å‹çš„å‰©ä½™ç»“æœ
            if baidu_index >= len(baidu_results):
                while quark_index < len(quark_results):
                    quark_results[quark_index]["type"] = "quark"
                    grouped_results.append(quark_results[quark_index])
                    quark_index += 1
            
            if quark_index >= len(quark_results):
                while baidu_index < len(baidu_results):
                    baidu_results[baidu_index]["type"] = "baidu"
                    grouped_results.append(baidu_results[baidu_index])
                    baidu_index += 1
        
        return grouped_results

    def format_paginated_results(self, user_id: str, all_results: list, pagination: dict) -> str:
        """æ ¼å¼åŒ–åˆ†é¡µç»“æœï¼ŒæŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„å±•ç¤º"""
        page = pagination["page"]
        per_page = pagination["per_page"]
        
        # è®¡ç®—å½“å‰é¡µçš„èµ·å§‹å’Œç»“æŸç´¢å¼•
        start_index = (page - 1) * per_page
        end_index = min(start_index + per_page, len(all_results))
        
        # è·å–å½“å‰é¡µçš„ç»“æœ
        page_results = all_results[start_index:end_index]
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = [f"ğŸ” æœç´¢ç»“æœ (ç¬¬ {page} é¡µ)ï¼š"]
        formatted_results.append("â•" * 30)
        
        # æŒ‰ç±»å‹åˆ†ç»„å±•ç¤º
        baidu_items = []
        quark_items = []
        
        for i, item in enumerate(page_results, 1):
            title = item.get("note", "æœªçŸ¥æ ‡é¢˜")
            if item.get("type") == "baidu":
                baidu_items.append(f"{i}. {title}")
            elif item.get("type") == "quark":
                quark_items.append(f"{i}. {title}")
        
        # å±•ç¤ºç™¾åº¦ç½‘ç›˜ç»“æœ
        if baidu_items:
            formatted_results.append("ğŸŒ ç™¾åº¦ç½‘ç›˜èµ„æº:")
            formatted_results.append("â”€" * 20)
            formatted_results.extend(baidu_items)
            formatted_results.append("")
        
        # å±•ç¤ºå¤¸å…‹ç½‘ç›˜ç»“æœ
        if quark_items:
            formatted_results.append("ğŸŒ å¤¸å…‹ç½‘ç›˜èµ„æº:")
            formatted_results.append("â”€" * 20)
            formatted_results.extend(quark_items)
        
        formatted_results.append("â•" * 30)
        
        # æ·»åŠ åˆ†é¡µä¿¡æ¯å’Œäº¤äº’æç¤º
        total_count = len(all_results)
        total_pages = (total_count + per_page - 1) // per_page
        formatted_results.append(f"ğŸ“ˆ å…± {total_count} æ¡ç»“æœï¼Œå½“å‰ç¬¬ {page}/{total_pages} é¡µ")
        formatted_results.append("ğŸ“Œ è¾“å…¥ 'è·å–+ç¼–å·' æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚ï¼šè·å–1ï¼‰")
        
        if page > 1:
            formatted_results.append("â¬…ï¸  å‘é€ 'ä¸Šä¸€é¡µ' æŸ¥çœ‹å‰ä¸€é¡µ")
        if page < total_pages:
            formatted_results.append("â¡ï¸  å‘é€ 'ä¸‹ä¸€é¡µ' æŸ¥çœ‹ä¸‹ä¸€é¡µ")
        
        return "\n".join(formatted_results)

    async def terminate(self):
        """æ’ä»¶é”€æ¯"""
        pass